{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68421b53",
   "metadata": {},
   "source": [
    "# Advanced aggregation operations in SQL\n",
    "\n",
    "In the last section, we learned about advanced joins. In similar fashion, aggregate functions, which were introduced in the [Introduction to SQL](https://ploomber-sql.readthedocs.io/en/latest/intro-to-sql/aggregate-functions-in-sql.html) module, also have advanced operations.\n",
    "\n",
    "Recall that aggregation functions are useful for summarizing your data and for finding meaningful insights. The most common of these functions are `COUNT()`, `AVG()`, `SUM()`, `MIN()`, `MAX()`, `GROUPBY()`, and `HAVING`. However, in this section, we will focus on operations that help us handle tasks that are hard to implement efficiently with\n",
    "basic aggregation features.\n",
    "\n",
    "Specifically, we will learn about ranking (`RANK()`), windowing (`OVER()`), pivoting (`PIVOT()`), and rollup (`ROLLUP()`).\n",
    "\n",
    "Let's first run the installations and setup before running any queries.\n",
    "\n",
    "<!-- region -->\n",
    "\n",
    "## Set up and data access\n",
    "\n",
    "```{important}\n",
    "<b>Note:</b> The `--save` and `%sqlcmd` features used require the latest JupySQL version. Ensure you run the code below to update JupySQL.\n",
    "```\n",
    "\n",
    "This code installs JupySQL, DuckDB, and Pandas in your environment. We will be using these moving forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cefcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install jupysql --upgrade duckdb-engine pandas --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ea845d",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "<b>Note:</b> If you are following these lessons locally and <b>not</b> on Google Colab, then there is no need to load the data again. \n",
    "\n",
    "This section was covered in detail in the tutorial: [Joining Data in SQL](https://ploomber-sql.readthedocs.io/en/latest/intro-to-sql/joining-data-in-sql.html#load-the-data). We will be using the same data in this tutorial as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c80b76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"../../\")\n",
    "import banking  # noqa: E402\n",
    "\n",
    "\n",
    "_ = banking.MarketData(\"https://tinyurl.com/jb-bank-m\", \"expanded_data\")\n",
    "_.extract_asc_to_csv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0cd862",
   "metadata": {},
   "source": [
    "If you ran the above cell, you should have a folder `expanded_data` in your current directory that contains the `.csv` files we will be using. However, in this tutorial, we will focus on one file: `loan.csv`.\n",
    "\n",
    "## Load Engine\n",
    "We now load in our SQL extension that allows us to execute SQL queries in Jupyter Notebooks.\n",
    "\n",
    "<b>Note</b> Ensure you restart any previous notebook that has the same database name as the one initialized below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42672357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading in SQL extension\n",
    "%reload_ext sql\n",
    "# Initiating a DuckDB database named 'bank_data.duck.db' to run SQL queries\n",
    "%sql duckdb:///bank_data.duck.db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c269ee30",
   "metadata": {},
   "source": [
    "Let's now return to our initial dataset of bank marketing records.\n",
    "\n",
    "## Queries\n",
    "\n",
    "### Creating Table\n",
    "\n",
    "Let's start off with loading the `loan.csv` file from the `expanded_data` folder in the current directory to our newly created DuckDB database. Because we will be working with one table, [creating a schema](https://ploomber-sql.readthedocs.io/en/latest/intro-to-sql/joining-data-in-sql.html#creating-a-schema) is not required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f4719b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "CREATE TABLE loan AS\n",
    "FROM read_csv_auto('expanded_data/loan.csv', header=True, sep=',');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b295ceda",
   "metadata": {},
   "source": [
    "### Ranking\n",
    "\n",
    "`RANK()` finds the position of a value within a result set. For instance, we may wish to assign customers a rank based on the date when the loan was granted, with the rank 1 going to the customer with the highest date, the rank 2 to the customer with the next highest date, and so on.\n",
    "\n",
    "<b>Note:</b> The `date` variable in the `loan` data is an integer, in the format YYMMDD, and will be used throughout the examples below.\n",
    "\n",
    "#### General Syntax\n",
    "\n",
    "The general syntax of the rank function is:\n",
    "\n",
    "```python\n",
    "%%sql \n",
    "RANK() OVER (ORDER BY expr [ASC|DESC] [, expr [ASC|DESC]] ...)\n",
    "```\n",
    "\n",
    "`RANK()` is executed by the attributes (or expressions) specified in the `OVER (ORDER BY())` clause. <b>Without this clause, `RANK()` will return the same value for each row</b>. \n",
    "\n",
    "Each order by expression optionally it can be followed by `ASC` or `DESC` to indicate the sort direction. <b>The default is `ASC` if no direction is specified</b>. `NULL` values are sorted first for ascending sorts and last for descending sorts.\n",
    "\n",
    "The following query gives the rank of each customer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665e2dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql \n",
    "SELECT account_id, RANK() OVER (ORDER BY (date) DESC) AS c_rank\n",
    "FROM loan;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1aab69d",
   "metadata": {},
   "source": [
    "Although the tuples above are ordered by rank, sometimes they may not. Therefore, an extra, outer `ORDER BY()` clause is needed to ensure they are:\n",
    "\n",
    "```python\n",
    "%%sql \n",
    "SELECT account_id, RANK() OVER (ORDER BY (date) DESC) as c_rank\n",
    "FROM loan\n",
    "ORDER BY c_rank;\n",
    "```\n",
    "\n",
    "```{important}\n",
    "The `RANK()` function gives the same rank to all tuples that are equal on the `ORDER BY()` attributes. For instance, if the highest date is shared by two customers, both would get rank 1. The next rank given would be 3, not 2, so if three customers have the next highest date, they would all get rank 3, and the next 10 customer(s) would get rank 6, and so on. \n",
    "```\n",
    "\n",
    "There is also a `DENSE_RANK` clause that does not create gaps in the ordering and an example is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b0ef6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql \n",
    "SELECT account_id, RANK() OVER (ORDER BY (date) DESC) as c_rank, DENSE_RANK() OVER (ORDER BY (date) DESC) AS d_rank\n",
    "FROM loan\n",
    "ORDER BY c_rank;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11731a7",
   "metadata": {},
   "source": [
    "Several other functions can be used apart from `RANK` or `DENSE_RANK`:\n",
    "\n",
    "- `PERCENT_RANK` returns the rank of each tuple as a fraction between 0 and 1\n",
    "- `CUME_DIST` returns the cumulative distribution of each tuple\n",
    "- `NTILE` takes tuples in each partition (more below!) and divides them into buckets\n",
    "- `ROW_NUMBER` sorts the rows and gives each row a unique number corresponding to its position in the sort order\n",
    "\n",
    "#### Partitioning/Grouping\n",
    "\n",
    "`RANK()` can also be used to rank tuples within groups. For instance, we may wish to rank customers by the date when the loan was granted, grouped by their status of paying off the loan. This can be done by partitioning the tuples, with a `PARTITION BY` clause within `OVER()`, by `status` (A, B, C, or D) and then ordering them by `date` within each `status`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6550ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT account_id, status, DENSE_RANK() OVER (PARTITION BY status ORDER BY (date) DESC) AS grouped_rank\n",
    "FROM loan\n",
    "ORDER BY grouped_rank;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603bead3",
   "metadata": {},
   "source": [
    "For reference, the different statuses represent:\n",
    "\n",
    "- 'A' stands for contract finished, no problems\n",
    "- 'B' stands for contract finished, loan not payed\n",
    "- 'C' stands for running contract, OK so far\n",
    "- 'D' stands for running contract, client in debt\n",
    "\n",
    "#### Question 1 (Medium):\n",
    "Rank, in <b>descending</b> order, the customers by the `date` when the loan was granted, grouped by their `status` of paying off the loan. Also, find the average loan `amount` of customers by `status` and `date` and round it to 0 decimal places.\n",
    "\n",
    "<b>Hint</b> Think about which basic aggregation clauses you will need to use to find the average loan amount by `status` and `date`. Once that is done, arrange the tuples in descending order of their rank.\n",
    "\n",
    "<!-- #region -->\n",
    "<details>\n",
    "\n",
    "<summary>Answers</summary>\n",
    "\n",
    "The SQL query here is very similar to the `DENSE_RANK` query above. The only difference is that we need to find the average loan amount by `status` and `date` and round it to 0 decimal places. To do this we need two basic aggregation clauses: `AVG()` and `GROUP BY()`. Without the `GROUP BY()` clause, the appropriate average amount cannot be found. Moreover, the correct columns need to be specified in it, including `account_id`, `status`, and `date`, to obtain the rank of each customer by `status` and `date`. Lastly, to order the tuples in descending order of their rank, we need to add the `DESC` clause."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b3d647",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT account_id, status, ROUND(AVG(amount), 0) as avg_amount, DENSE_RANK() OVER (PARTITION BY status ORDER BY date DESC) AS grouped_rank\n",
    "FROM loan\n",
    "GROUP BY account_id, status, date\n",
    "ORDER BY grouped_rank DESC;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a97efc",
   "metadata": {},
   "source": [
    "```{important}\n",
    "Try changing the `DENSE_RANK()` clause to `RANK()`. What do you notice? Why do you think this is the case?\n",
    "```\n",
    "\n",
    "</details>\n",
    "<!-- #endregion -->\n",
    "\n",
    "### Windowing\n",
    "\n",
    "It is relatively easy to write an SQL query using those features we have already studied to compute an aggregate over one window, for example, loan amounts over a fixed 3-day period. However, if we want to do this for <b>every</b> 3-day period, like a moving-average, the query becomes cumbersome.\n",
    "\n",
    "Window queries compute an aggregate function over ranges of tuples by accessing the records right before or after the current record. A set of rows to which this aggregation function applies to is referred to as a <b>window</b>. \n",
    "\n",
    "```{important}\n",
    "Windows may overlap, in which case a tuple may contribute to more than one window. <b>This is unlike the partitions we learnt about earlier</b>, where a tuple could contribute to only one partition.\n",
    "```\n",
    "\n",
    "#### General Syntax\n",
    "\n",
    "Windowing is performed with the following syntax: `OVER` ( [partition] [order] [frame] )\n",
    "\n",
    "It allows a <b>frame</b> to move within a partition depending on the position of the current row within its partition. The offsets of the current row and frame rows are the <b>row numbers</b> if the frame unit is `ROWS` and <b>row values</b> if the frame unit is `RANGE`.\n",
    "\n",
    "Frames and its operations can be represented with the following:\n",
    "\n",
    "- frame: {<i>frame_start</i> | <i>frame_between</i>}\n",
    "\n",
    "- frame_between: `BETWEEN` <i>frame_start</i> AND <i>frame_end</i>\n",
    "\n",
    "- frame_start, frame_end: {\n",
    "  `CURRENT ROW`\n",
    "  | `UNBOUNDED PRECEDING`\n",
    "  | `UNBOUNDED FOLLOWING`\n",
    "  | <i>expr</i>  `PRECEDING`\n",
    "  | <i>expr</i>  `FOLLOWING` }\n",
    "\n",
    "![](windowing.jpg)\n",
    "\n",
    "#### Examples\n",
    "\n",
    "1. The first 14 rows of the `loan` table have unique, non-consecutive dates ranging from July 5th 1993 to December 1st 1993. Therefore, we can compute the average loan amount over the three preceding tuples in the specified sort order. Note that this example makes sense only because each date, for the first 14 records, appears only once in `loan`. The example is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc41473e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT date, AVG(amount) OVER (ORDER BY date ROWS 3 PRECEDING) AS avg_amount\n",
    "FROM loan\n",
    "WHERE date <= 931201;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b8d632",
   "metadata": {},
   "source": [
    "This is not the case across the whole table, which means there are several possible orderings of tuples since tuples for the same date could be in any order. To tackle this, we introduce in the example below a windowing query that uses a <b>range</b> of values instead of a specific number of tuples.\n",
    "\n",
    "2. Suppose that instead of going back a fixed number of tuples, we want the window to consist of all prior dates. That means the number of prior dates considered is not fixed and, hence, we can perform this on the entire dataset. To get the average amount over all prior dates, we write:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a70382b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT date, AVG(amount) OVER (ORDER BY date RANGE UNBOUNDED PRECEDING) AS avg_amount\n",
    "FROM loan;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13552210",
   "metadata": {},
   "source": [
    "```{important}\n",
    "The `ROUND()` function is not recognized as an aggregate function in DuckDB. In the above query, If we modified the above `SELECT` clause to have `ROUND(AVG(amount),0)`, we would get an error because we tried to use the `ROUND()` function within the `OVER` clause, which is not supported in DuckDB. To fix it, use a subquery in the `FROM` clause as follows:\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73ebd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT date, ROUND(avg_amount, 2) AS rounded_avg_amount\n",
    "FROM (SELECT date, AVG(amount) OVER (ORDER BY date ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING) AS avg_amount FROM loan);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36297044",
   "metadata": {},
   "source": [
    "<b>Note:</b> It is possible to use the keyword `FOLLOWING` in place of `PRECEDING`. If we did this in our example, the year value specifies the beginning of the window instead of the end. However, we will need to specify it using `BETWEEN`, explained below!\n",
    "\n",
    "3. Using `BETWEEN` for `UNBOUNDED FOLLOWING` is necessary because DuckDB does not allow a frame to start with `UNBOUNDED FOLLOWING`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5079ac7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT date, ROUND(avg_amount, 2) AS rounded_avg_amount\n",
    "FROM (SELECT date, AVG(amount) OVER (ORDER BY date ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING) AS avg_amount FROM loan);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5a82aa",
   "metadata": {},
   "source": [
    "#### Question 2 (Hard):\n",
    "\n",
    "Return the maximum loan `amount`, rounded to 0 decimals, by the customer's `status` for paying off the loan for every three dates preceding and every two dates following the current date of a tuple . Also, order the output by ascending order of `date`.\n",
    "\n",
    "<b>Hint</b> Think about which advanced aggregation clause is needed to return the loan `amount` by `status`. Then, think about how to build the query for rounding the values.\n",
    "\n",
    "<!-- #region -->\n",
    "<details>\n",
    "\n",
    "<summary>Answers</summary>\n",
    "\n",
    "The SQL query here is very similar to the third windowing function example. We can write windowing queries that treat each status separately by partitioning by `status`. Therefore, we need to add a `PARTITION BY` clause before the `ORDER BY` clause, like the ranking example, to account for `status`, use the `MAX` aggregation clause instead of `AVG`, add an extra `ORDER BY` clause at the end of the query, and change the frame selection to include both `PRECEDING` and `FOLLOWING` as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08c78d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT date, status, ROUND(max_amount, 0) AS rounded_max_amount\n",
    "FROM (SELECT date, status, MAX(amount) OVER (PARTITION BY status ORDER BY date ROWS BETWEEN 3 PRECEDING AND 2 FOLLOWING) AS max_amount FROM loan)\n",
    "ORDER BY date;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc98a5c",
   "metadata": {},
   "source": [
    "Try playing around with different frame selections and aggregation functions to develop your intuition!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192598dd",
   "metadata": {},
   "source": [
    "</details>\n",
    "<!-- #endregion -->\n",
    "\n",
    "### Pivoting\n",
    "\n",
    "Using SQL aggregation functions, we can easily create cross-tabulations (or cross-tabs for short), which takes a column of data and turns it into multiple columns, one for each unique value in the original column. It can also perform aggregations on the data, such as calculating the average or sum of the values in each column, useful for summarizing data.\n",
    "\n",
    "```{important}\n",
    "DuckDB supports the `PIVOT` operator, but other databases, such as MySQL, do not. Yet, pivoting can be made possible and we shall explore below.\n",
    "```\n",
    "\n",
    "#### General Syntax\n",
    "\n",
    "The syntax for `PIVOT` is as follows:\n",
    "\n",
    "```python\n",
    "PIVOT [dataset] \n",
    "ON [column(s)] \n",
    "USING [value(s)] \n",
    "GROUP BY [row(s)]\n",
    "```\n",
    "\n",
    "For other databases (and DuckDB), the `CASE WHEN` clause can be used to pivot data:\n",
    "\n",
    "```python\n",
    "SELECT pivot_column,\n",
    "SUM(\n",
    "    CASE \n",
    "        WHEN pivot_column = pivot_value THEN aggregate_column\n",
    "        WHEN pivot_column = pivot_value THEN aggregate_column\n",
    "        ELSE 0\n",
    "    END\n",
    ") AS alias\n",
    "FROM table\n",
    "GROUP BY pivot_column;\n",
    "```\n",
    "\n",
    "#### Examples\n",
    "\n",
    "Suppose we want to obtain the total loan `amount` by both the customer's `status` of paying off the loan and the `duration` of the loan. We can do this by pivoting the `status` column, summing the `amount` column, and grouping the `duration` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd3b28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "PIVOT loan ON status USING SUM(amount) GROUP BY duration;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58716e3d",
   "metadata": {},
   "source": [
    "Using, `CASE WHEN` we get identical results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6eb2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT duration,\n",
    "    SUM(CASE WHEN status = 'A' THEN amount ELSE 0 END) AS A,\n",
    "    SUM(CASE WHEN status = 'B' THEN amount ELSE 0 END) AS B,\n",
    "    SUM(CASE WHEN status = 'C' THEN amount ELSE 0 END) AS C,\n",
    "    SUM(CASE WHEN status = 'D' THEN amount ELSE 0 END) AS D,\n",
    "FROM loan\n",
    "GROUP BY duration;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99245aaa",
   "metadata": {},
   "source": [
    "#### Question 3 (Medium):\n",
    "\n",
    "For all the customers' `status` of paying off the loan, `duration` of the loan, and `date` of the loan, return both the average loan `amount`. Make sure to return `date` in the first column and only those columns that have combinations of `status` and `duration` values in them (i.e no columns with only `None` values should be displayed).\n",
    "\n",
    "<b>Hint</b> Because the output should contain the `date` column first, we use a `GROUP BY` for it. Multiple `ON` columns and expressions can be specified in the `PIVOT` clause along with multiple `USING` expressions. The expression `||'_'||` can be used not only to concatenate the columns, but also to pivot only the combinations of values that are present in the data. The order of the columns will, hence, be: date, A_12_sum(amount), A_24_sum(amount), A_36_sum(amount),..., D_60_sum(amount)\n",
    "\n",
    "<!-- #region -->\n",
    "<details>\n",
    "\n",
    "<summary>Answers</summary>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49c0c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "PIVOT loan ON status ||'_'|| duration USING SUM(amount) GROUP BY date;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc55071",
   "metadata": {},
   "source": [
    "Try playing with multiple variables in the `ON`, `USING`, and `GROUP BY` clauses and see if you can explore the data more closely!\n",
    "\n",
    "</details>\n",
    "<!-- #endregion -->\n",
    "\n",
    "### Grouping Sets, Rollup, and Cube\n",
    "\n",
    "To perform a grouping over multiple dimensions within the same query, the following clauses can be used with `GROUP BY`:\n",
    "\n",
    "- `GROUPING SETS` perform the same aggregate across different `GROUP BY` clauses in a single query.\n",
    "- `ROLLUP` produces all <b>“sub-groups”</b> of a grouping set, e.g. `ROLLUP (country, city, zip)` produces the grouping sets (country, city, zip), (country, city), (country), () where () denotes an <b>empty group by</b> list. Therefore, placement of variables matters here because only the first variable's individual aggregation is output. This produces <b>n+1 grouping sets</b> where n is the number of terms in the `ROLLUP` clause.\n",
    "- `CUBE`: produces grouping sets for all combinations of the inputs, e.g. `CUBE (country, city, zip)` will produce (country, city, zip), (country, city), (country, zip), (city, zip), (country), (city), (zip), (). This produces <b>2^n grouping sets</b>.\n",
    "\n",
    "```{important}\n",
    "Neither the `ROLLUP` nor the CUBE` clause gives complete control on the groupings that are generated. Therefore, `GROUPING SETS` is the most flexible of the three.\n",
    "```\n",
    "\n",
    "#### Examples\n",
    "\n",
    "Suppose we want to obtain the number of `account_id`'s by the customer's `status` of paying off the loan and the `duration` of the loan together and separately. We can do this by using `GROUPING SETS`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303eab29",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT status, duration, COUNT(account_id) AS count_account_id\n",
    "FROM loan\n",
    "GROUP BY GROUPING SETS ((), status, (status, duration), duration);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8af1dc",
   "metadata": {},
   "source": [
    "Using `CUBE`, which helps us condense the above `GROUP BY` clause, we can get identical results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e6dcfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT status, duration, COUNT(account_id) AS count_account_id\n",
    "FROM loan\n",
    "GROUP BY CUBE (status, duration);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6270450e",
   "metadata": {},
   "source": [
    "#### Question 4 (Easy):\n",
    "\n",
    "Find the maximum loan `amount` in the following groupings: {(date, duration), (status, duration)}.\n",
    "\n",
    "<!-- #region -->\n",
    "<details>\n",
    "\n",
    "<summary>Answers</summary>\n",
    "\n",
    "Recall the note at the beginning of this section, which stated that neither `ROLLUPS` nor `CUBE` can be used to specify restricted groupings, like in the question above. Therefore, we use `GROUPING SETS`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1e7cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT date, duration, status, MAX(amount) AS max_amount\n",
    "FROM loan\n",
    "GROUP BY GROUPING SETS ((date, duration), (status, duration));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b59c2c0",
   "metadata": {},
   "source": [
    "</details>\n",
    "<!-- #endregion -->\n",
    "\n",
    "## Wrapping Up\n",
    "\n",
    "In this section, we introduced advanced aggregation functions. To summarize:\n",
    "\n",
    "- `RANK()` : Returns the rank of each row in the result set. It needs to be used with the `OVER (ORDER BY())` clause. It can also be used with `PARTITION BY` to rank within a group.\n",
    "\n",
    "- Windowing : Helps obtain moving-aggregations either through the whole dataset or a subset of it, depending on the frame selection. Executed with the syntax `OVER` ( [partition] [order] [frame] ).\n",
    "\n",
    "- `PIVOT()` : Produces a cross-tab for summarizing datasets based on one or many column(s). Can be emulated with `CASE WHEN` statements for compatibility with other SQL dialects.\n",
    "\n",
    "- Groupings : `GROUPING SETS` provides the most flexibility out of `ROLLUP` and `CUBE`.\n",
    "\n",
    "This ends the module <b>Advanced querying techniques</b> and we hope you enjoyed it! Next, we will learn about how to visualize your queries using popular Python libraries, including `matplotlib` and `seaborn`, and `ggplot`!\n",
    "\n",
    "<!-- #endregion -->\n",
    "\n",
    "## References\n",
    "\n",
    "Silberschatz, A., Korth, H. F., &amp; Sudarshan, S. (2020). Database system concepts. McGraw-Hill.\n",
    "\n",
    "DuckDB. (n.d.). https://duckdb.org/docs/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
